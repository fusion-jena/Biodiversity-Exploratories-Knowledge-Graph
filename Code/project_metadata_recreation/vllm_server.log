INFO 09-06 10:12:35 [__init__.py:241] Automatically detected platform cuda.
[1;36m(APIServer pid=3722631)[0;0m INFO 09-06 10:12:37 [api_server.py:1805] vLLM API server version 0.10.1.1
[1;36m(APIServer pid=3722631)[0;0m INFO 09-06 10:12:37 [utils.py:326] non-default args: {'model_tag': 'mistralai/Mistral-Small-3.2-24B-Instruct-2506', 'host': '0.0.0.0', 'enable_auto_tool_choice': True, 'tool_call_parser': 'mistral', 'model': 'mistralai/Mistral-Small-3.2-24B-Instruct-2506', 'tokenizer_mode': 'mistral', 'max_model_len': 8192, 'enforce_eager': True, 'config_format': 'mistral', 'load_format': 'mistral', 'download_dir': '/home/pa93wax/Documents/project_metadata_recreation/runs/hf_cache', 'disable_custom_all_reduce': True}
[1;36m(APIServer pid=3722631)[0;0m INFO 09-06 10:12:43 [__init__.py:711] Resolved architecture: PixtralForConditionalGeneration
[1;36m(APIServer pid=3722631)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=3722631)[0;0m Parse safetensors files:   0%|          | 0/10 [00:00<?, ?it/s]Parse safetensors files:  10%|â–ˆ         | 1/10 [00:00<00:03,  2.56it/s]Parse safetensors files:  20%|â–ˆâ–ˆ        | 2/10 [00:00<00:01,  4.02it/s]Parse safetensors files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 18.50it/s]
[1;36m(APIServer pid=3722631)[0;0m INFO 09-06 10:12:44 [__init__.py:1750] Using max model len 8192
[1;36m(APIServer pid=3722631)[0;0m INFO 09-06 10:12:44 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.
[1;36m(APIServer pid=3722631)[0;0m INFO 09-06 10:12:44 [__init__.py:3565] Cudagraph is disabled under eager mode
[1;36m(APIServer pid=3722631)[0;0m /tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/mistral_common/tokens/tokenizers/tekken.py:337: FutureWarning: The attributed `special_token_policy` is deprecated and will be removed in 1.10.0. Please pass a special token policy explicitly to the relevant methods.
[1;36m(APIServer pid=3722631)[0;0m   warnings.warn(
[1;36m(APIServer pid=3722631)[0;0m The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
INFO 09-06 10:12:49 [__init__.py:241] Automatically detected platform cuda.
[1;36m(EngineCore_0 pid=3722774)[0;0m INFO 09-06 10:12:51 [core.py:636] Waiting for init message from front-end.
[1;36m(EngineCore_0 pid=3722774)[0;0m INFO 09-06 10:12:51 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='mistralai/Mistral-Small-3.2-24B-Instruct-2506', speculative_config=None, tokenizer='mistralai/Mistral-Small-3.2-24B-Instruct-2506', skip_tokenizer_init=False, tokenizer_mode=mistral, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir='/home/pa93wax/Documents/project_metadata_recreation/runs/hf_cache', load_format=mistral, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-Small-3.2-24B-Instruct-2506, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_0 pid=3722774)[0;0m INFO 09-06 10:12:51 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_0 pid=3722774)[0;0m /tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/mistral_common/tokens/tokenizers/tekken.py:337: FutureWarning: The attributed `special_token_policy` is deprecated and will be removed in 1.10.0. Please pass a special token policy explicitly to the relevant methods.
[1;36m(EngineCore_0 pid=3722774)[0;0m   warnings.warn(
[1;36m(EngineCore_0 pid=3722774)[0;0m WARNING 09-06 10:12:52 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_0 pid=3722774)[0;0m WARNING 09-06 10:12:53 [registry.py:183] PixtralProcessorAdapter did not return `BatchFeature`. Make sure to match the behaviour of `ProcessorMixin` when implementing custom processors.
[1;36m(EngineCore_0 pid=3722774)[0;0m /tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/mistral_common/tokens/tokenizers/tekken.py:461: FutureWarning: Using the tokenizer's special token policy (SpecialTokenPolicy.IGNORE) is deprecated. It will be removed in 1.10.0. Please pass a special token policy explicitly. Future default will be SpecialTokenPolicy.IGNORE.
[1;36m(EngineCore_0 pid=3722774)[0;0m   warnings.warn(
[1;36m(EngineCore_0 pid=3722774)[0;0m INFO 09-06 10:12:53 [gpu_model_runner.py:1953] Starting to load model mistralai/Mistral-Small-3.2-24B-Instruct-2506...
[1;36m(EngineCore_0 pid=3722774)[0;0m INFO 09-06 10:12:53 [gpu_model_runner.py:1985] Loading model from scratch...
[1;36m(EngineCore_0 pid=3722774)[0;0m INFO 09-06 10:12:53 [__init__.py:3565] Cudagraph is disabled under eager mode
[1;36m(EngineCore_0 pid=3722774)[0;0m INFO 09-06 10:12:53 [cuda.py:328] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700] EngineCore failed to start.
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700] Traceback (most recent call last):
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 691, in run_engine_core
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 492, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 80, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self._init_executor()
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 49, in _init_executor
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.collective_rpc("load_model")
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 58, in collective_rpc
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     answer = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/utils/__init__.py", line 3007, in run_method
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     return func(*args, **kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 212, in load_model
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1986, in load_model
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.model = model_loader.load_model(
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 44, in load_model
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/pixtral.py", line 360, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.language_model = init_vllm_registered_model(
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 316, in init_vllm_registered_model
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     return initialize_model(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 517, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.model = self._init_model(vllm_config=vllm_config,
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 563, in _init_model
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     return LlamaModel(vllm_config=vllm_config,
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 183, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 339, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 641, in make_layers
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 341, in <lambda>
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     lambda prefix: layer_type(config=config,
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                    ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 272, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.mlp = LlamaMLP(
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                ^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 72, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 649, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     super().__init__(input_size=input_size,
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 508, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     self.quant_method.create_weights(
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 193, in create_weights
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]     return func(*args, **kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m ERROR 09-06 10:12:54 [core.py:700] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 39.43 GiB of which 281.81 MiB is free. Including non-PyTorch memory, this process has 39.15 GiB memory in use. Of the allocated memory 38.67 GiB is allocated by PyTorch, and 8.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;36m(EngineCore_0 pid=3722774)[0;0m Process EngineCore_0:
[1;36m(EngineCore_0 pid=3722774)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/cluster/ecosystems/anaconda3/2024.10/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.run()
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/cluster/ecosystems/anaconda3/2024.10/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_0 pid=3722774)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 704, in run_engine_core
[1;36m(EngineCore_0 pid=3722774)[0;0m     raise e
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 691, in run_engine_core
[1;36m(EngineCore_0 pid=3722774)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 492, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 80, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_0 pid=3722774)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     self._init_executor()
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 49, in _init_executor
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.collective_rpc("load_model")
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 58, in collective_rpc
[1;36m(EngineCore_0 pid=3722774)[0;0m     answer = run_method(self.driver_worker, method, args, kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/utils/__init__.py", line 3007, in run_method
[1;36m(EngineCore_0 pid=3722774)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 212, in load_model
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.model_runner.load_model(eep_scale_up=eep_scale_up)
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1986, in load_model
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.model = model_loader.load_model(
[1;36m(EngineCore_0 pid=3722774)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/base_loader.py", line 44, in load_model
[1;36m(EngineCore_0 pid=3722774)[0;0m     model = initialize_model(vllm_config=vllm_config,
[1;36m(EngineCore_0 pid=3722774)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_0 pid=3722774)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_0 pid=3722774)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/pixtral.py", line 360, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.language_model = init_vllm_registered_model(
[1;36m(EngineCore_0 pid=3722774)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 316, in init_vllm_registered_model
[1;36m(EngineCore_0 pid=3722774)[0;0m     return initialize_model(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_0 pid=3722774)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/model_loader/utils.py", line 63, in initialize_model
[1;36m(EngineCore_0 pid=3722774)[0;0m     return model_class(vllm_config=vllm_config, prefix=prefix)
[1;36m(EngineCore_0 pid=3722774)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 517, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.model = self._init_model(vllm_config=vllm_config,
[1;36m(EngineCore_0 pid=3722774)[0;0m                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 563, in _init_model
[1;36m(EngineCore_0 pid=3722774)[0;0m     return LlamaModel(vllm_config=vllm_config,
[1;36m(EngineCore_0 pid=3722774)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 183, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 339, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.start_layer, self.end_layer, self.layers = make_layers(
[1;36m(EngineCore_0 pid=3722774)[0;0m                                                     ^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 641, in make_layers
[1;36m(EngineCore_0 pid=3722774)[0;0m     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
[1;36m(EngineCore_0 pid=3722774)[0;0m                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 341, in <lambda>
[1;36m(EngineCore_0 pid=3722774)[0;0m     lambda prefix: layer_type(config=config,
[1;36m(EngineCore_0 pid=3722774)[0;0m                    ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 272, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.mlp = LlamaMLP(
[1;36m(EngineCore_0 pid=3722774)[0;0m                ^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 72, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.gate_up_proj = MergedColumnParallelLinear(
[1;36m(EngineCore_0 pid=3722774)[0;0m                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 649, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     super().__init__(input_size=input_size,
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 508, in __init__
[1;36m(EngineCore_0 pid=3722774)[0;0m     self.quant_method.create_weights(
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 193, in create_weights
[1;36m(EngineCore_0 pid=3722774)[0;0m     weight = Parameter(torch.empty(sum(output_partition_sizes),
[1;36m(EngineCore_0 pid=3722774)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/torch/utils/_device.py", line 104, in __torch_function__
[1;36m(EngineCore_0 pid=3722774)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_0 pid=3722774)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_0 pid=3722774)[0;0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 39.43 GiB of which 281.81 MiB is free. Including non-PyTorch memory, this process has 39.15 GiB memory in use. Of the allocated memory 38.67 GiB is allocated by PyTorch, and 8.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[rank0]:[W906 10:12:54.074280745 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(APIServer pid=3722631)[0;0m Traceback (most recent call last):
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/bin/vllm", line 7, in <module>
[1;36m(APIServer pid=3722631)[0;0m     sys.exit(main())
[1;36m(APIServer pid=3722631)[0;0m              ^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/entrypoints/cli/main.py", line 54, in main
[1;36m(APIServer pid=3722631)[0;0m     args.dispatch_function(args)
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/entrypoints/cli/serve.py", line 50, in cmd
[1;36m(APIServer pid=3722631)[0;0m     uvloop.run(run_server(args))
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/uvloop/__init__.py", line 109, in run
[1;36m(APIServer pid=3722631)[0;0m     return __asyncio.run(
[1;36m(APIServer pid=3722631)[0;0m            ^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/cluster/ecosystems/anaconda3/2024.10/lib/python3.12/asyncio/runners.py", line 194, in run
[1;36m(APIServer pid=3722631)[0;0m     return runner.run(main)
[1;36m(APIServer pid=3722631)[0;0m            ^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/cluster/ecosystems/anaconda3/2024.10/lib/python3.12/asyncio/runners.py", line 118, in run
[1;36m(APIServer pid=3722631)[0;0m     return self._loop.run_until_complete(task)
[1;36m(APIServer pid=3722631)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "uvloop/loop.pyx", line 1518, in uvloop.loop.Loop.run_until_complete
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/uvloop/__init__.py", line 61, in wrapper
[1;36m(APIServer pid=3722631)[0;0m     return await main
[1;36m(APIServer pid=3722631)[0;0m            ^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 1850, in run_server
[1;36m(APIServer pid=3722631)[0;0m     await run_server_worker(listen_address, sock, args, **uvicorn_kwargs)
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 1870, in run_server_worker
[1;36m(APIServer pid=3722631)[0;0m     async with build_async_engine_client(
[1;36m(APIServer pid=3722631)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/cluster/ecosystems/anaconda3/2024.10/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=3722631)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=3722631)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 178, in build_async_engine_client
[1;36m(APIServer pid=3722631)[0;0m     async with build_async_engine_client_from_engine_args(
[1;36m(APIServer pid=3722631)[0;0m                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/cluster/ecosystems/anaconda3/2024.10/lib/python3.12/contextlib.py", line 210, in __aenter__
[1;36m(APIServer pid=3722631)[0;0m     return await anext(self.gen)
[1;36m(APIServer pid=3722631)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/entrypoints/openai/api_server.py", line 220, in build_async_engine_client_from_engine_args
[1;36m(APIServer pid=3722631)[0;0m     async_llm = AsyncLLM.from_vllm_config(
[1;36m(APIServer pid=3722631)[0;0m                 ^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/utils/__init__.py", line 1557, in inner
[1;36m(APIServer pid=3722631)[0;0m     return fn(*args, **kwargs)
[1;36m(APIServer pid=3722631)[0;0m            ^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/async_llm.py", line 174, in from_vllm_config
[1;36m(APIServer pid=3722631)[0;0m     return cls(
[1;36m(APIServer pid=3722631)[0;0m            ^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/async_llm.py", line 120, in __init__
[1;36m(APIServer pid=3722631)[0;0m     self.engine_core = EngineCoreClient.make_async_mp_client(
[1;36m(APIServer pid=3722631)[0;0m                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 102, in make_async_mp_client
[1;36m(APIServer pid=3722631)[0;0m     return AsyncMPClient(*client_args)
[1;36m(APIServer pid=3722631)[0;0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 767, in __init__
[1;36m(APIServer pid=3722631)[0;0m     super().__init__(
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 446, in __init__
[1;36m(APIServer pid=3722631)[0;0m     with launch_core_engines(vllm_config, executor_class,
[1;36m(APIServer pid=3722631)[0;0m          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(APIServer pid=3722631)[0;0m   File "/cluster/ecosystems/anaconda3/2024.10/lib/python3.12/contextlib.py", line 144, in __exit__
[1;36m(APIServer pid=3722631)[0;0m     next(self.gen)
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 706, in launch_core_engines
[1;36m(APIServer pid=3722631)[0;0m     wait_for_engine_startup(
[1;36m(APIServer pid=3722631)[0;0m   File "/tmp/srv_4414379_XpKg/venv/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 759, in wait_for_engine_startup
[1;36m(APIServer pid=3722631)[0;0m     raise RuntimeError("Engine core initialization failed. "
[1;36m(APIServer pid=3722631)[0;0m RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
INFO 09-06 10:17:07 [__init__.py:241] Automatically detected platform cuda.
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:17:09 [api_server.py:1805] vLLM API server version 0.10.1.1
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:17:09 [utils.py:326] non-default args: {'model_tag': 'mistralai/Mistral-Small-3.2-24B-Instruct-2506', 'host': '0.0.0.0', 'enable_auto_tool_choice': True, 'tool_call_parser': 'mistral', 'model': 'mistralai/Mistral-Small-3.2-24B-Instruct-2506', 'tokenizer_mode': 'mistral', 'max_model_len': 8192, 'enforce_eager': True, 'config_format': 'mistral', 'load_format': 'mistral', 'download_dir': '/home/pa93wax/Documents/project_metadata_recreation/runs/hf_cache', 'disable_custom_all_reduce': True}
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:17:14 [__init__.py:711] Resolved architecture: PixtralForConditionalGeneration
[1;36m(APIServer pid=1465994)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=1465994)[0;0m Parse safetensors files:   0%|          | 0/10 [00:00<?, ?it/s]Parse safetensors files:  10%|â–ˆ         | 1/10 [00:00<00:05,  1.64it/s]Parse safetensors files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 16.31it/s]
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:17:15 [__init__.py:1750] Using max model len 8192
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:17:16 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:17:16 [__init__.py:3565] Cudagraph is disabled under eager mode
[1;36m(APIServer pid=1465994)[0;0m /tmp/srv_4414382_obfD/venv/lib/python3.12/site-packages/mistral_common/tokens/tokenizers/tekken.py:337: FutureWarning: The attributed `special_token_policy` is deprecated and will be removed in 1.10.0. Please pass a special token policy explicitly to the relevant methods.
[1;36m(APIServer pid=1465994)[0;0m   warnings.warn(
[1;36m(APIServer pid=1465994)[0;0m The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
INFO 09-06 10:17:21 [__init__.py:241] Automatically detected platform cuda.
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:17:22 [core.py:636] Waiting for init message from front-end.
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:17:22 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='mistralai/Mistral-Small-3.2-24B-Instruct-2506', speculative_config=None, tokenizer='mistralai/Mistral-Small-3.2-24B-Instruct-2506', skip_tokenizer_init=False, tokenizer_mode=mistral, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir='/home/pa93wax/Documents/project_metadata_recreation/runs/hf_cache', load_format=mistral, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=mistralai/Mistral-Small-3.2-24B-Instruct-2506, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:17:23 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_0 pid=1466141)[0;0m /tmp/srv_4414382_obfD/venv/lib/python3.12/site-packages/mistral_common/tokens/tokenizers/tekken.py:337: FutureWarning: The attributed `special_token_policy` is deprecated and will be removed in 1.10.0. Please pass a special token policy explicitly to the relevant methods.
[1;36m(EngineCore_0 pid=1466141)[0;0m   warnings.warn(
[1;36m(EngineCore_0 pid=1466141)[0;0m WARNING 09-06 10:17:24 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_0 pid=1466141)[0;0m WARNING 09-06 10:17:24 [registry.py:183] PixtralProcessorAdapter did not return `BatchFeature`. Make sure to match the behaviour of `ProcessorMixin` when implementing custom processors.
[1;36m(EngineCore_0 pid=1466141)[0;0m /tmp/srv_4414382_obfD/venv/lib/python3.12/site-packages/mistral_common/tokens/tokenizers/tekken.py:461: FutureWarning: Using the tokenizer's special token policy (SpecialTokenPolicy.IGNORE) is deprecated. It will be removed in 1.10.0. Please pass a special token policy explicitly. Future default will be SpecialTokenPolicy.IGNORE.
[1;36m(EngineCore_0 pid=1466141)[0;0m   warnings.warn(
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:17:24 [gpu_model_runner.py:1953] Starting to load model mistralai/Mistral-Small-3.2-24B-Instruct-2506...
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:17:25 [gpu_model_runner.py:1985] Loading model from scratch...
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:17:25 [__init__.py:3565] Cudagraph is disabled under eager mode
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:17:25 [cuda.py:328] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:17:25 [weight_utils.py:296] Using model weights format ['consolidated*.safetensors', '*.pt']
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:17:25 [weight_utils.py:349] No consolidated.safetensors.index.json found in remote.
[1;36m(EngineCore_0 pid=1466141)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]
[1;36m(EngineCore_0 pid=1466141)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [02:17<00:00, 137.51s/it]
[1;36m(EngineCore_0 pid=1466141)[0;0m Loading safetensors checkpoint shards: 100% Completed | 1/1 [02:17<00:00, 137.51s/it]
[1;36m(EngineCore_0 pid=1466141)[0;0m 
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:19:44 [default_loader.py:262] Loading weights took 138.19 seconds
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:19:44 [gpu_model_runner.py:2007] Model loading took 44.7560 GiB and 139.019571 seconds
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:19:44 [gpu_model_runner.py:2591] Encoder cache will be initialized with a budget of 3080 tokens, and profiled with 1 image items of the maximum feature size.
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:19:45 [gpu_worker.py:276] Available KV cache memory: 25.23 GiB
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:19:46 [kv_cache_utils.py:849] GPU KV cache size: 165,360 tokens
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:19:46 [kv_cache_utils.py:853] Maximum concurrency for 8,192 tokens per request: 20.19x
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:19:46 [core.py:214] init engine (profile, create kv cache, warmup model) took 1.82 seconds
[1;36m(EngineCore_0 pid=1466141)[0;0m INFO 09-06 10:19:47 [__init__.py:3565] Cudagraph is disabled under eager mode
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [loggers.py:142] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 10335
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [api_server.py:1611] Supported_tasks: ['generate']
[1;36m(APIServer pid=1465994)[0;0m WARNING 09-06 10:19:47 [__init__.py:1625] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [serving_responses.py:120] Using default chat sampling params from model: {'temperature': 0.15}
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [serving_responses.py:149] "auto" tool choice has been enabled please note that while the parallel_tool_calls client option is preset for compatibility reasons, it will be ignored.
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [serving_chat.py:94] "auto" tool choice has been enabled please note that while the parallel_tool_calls client option is preset for compatibility reasons, it will be ignored.
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [serving_chat.py:134] Using default chat sampling params from model: {'temperature': 0.15}
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [serving_completion.py:77] Using default completion sampling params from model: {'temperature': 0.15}
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [api_server.py:1880] Starting vLLM API server 0 on http://0.0.0.0:8000
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:36] Available routes are:
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /openapi.json, Methods: HEAD, GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /docs, Methods: HEAD, GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /docs/oauth2-redirect, Methods: HEAD, GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /redoc, Methods: HEAD, GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /health, Methods: GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /load, Methods: GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /ping, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /ping, Methods: GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /version, Methods: GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /pooling, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /classify, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /score, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /rerank, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /invocations, Methods: POST
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:19:47 [launcher.py:44] Route: /metrics, Methods: GET
[1;36m(APIServer pid=1465994)[0;0m INFO:     Started server process [1465994]
[1;36m(APIServer pid=1465994)[0;0m INFO:     Waiting for application startup.
[1;36m(APIServer pid=1465994)[0;0m INFO:     Application startup complete.
[1;36m(APIServer pid=1465994)[0;0m INFO:     127.0.0.1:58572 - "GET /health HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36560 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36568 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36580 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36584 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:21:00 [chat_utils.py:470] Detected the chat template content format to be 'string'. You can set `--chat-template-content-format` to override this.
[1;36m(APIServer pid=1465994)[0;0m WARNING 09-06 10:21:00 [chat_utils.py:378] 'add_generation_prompt' is not supported for mistral tokenizer, so it will be ignored.
[1;36m(APIServer pid=1465994)[0;0m WARNING 09-06 10:21:00 [chat_utils.py:382] 'continue_final_message' is not supported for mistral tokenizer, so it will be ignored.
[1;36m(APIServer pid=1465994)[0;0m /tmp/srv_4414382_obfD/venv/lib/python3.12/site-packages/mistral_common/tokens/tokenizers/tekken.py:461: FutureWarning: Using the tokenizer's special token policy (SpecialTokenPolicy.IGNORE) is deprecated. It will be removed in 1.10.0. Please pass a special token policy explicitly. Future default will be SpecialTokenPolicy.IGNORE.
[1;36m(APIServer pid=1465994)[0;0m   warnings.warn(
[1;36m(EngineCore_0 pid=1466141)[0;0m WARNING 09-06 10:21:00 [cudagraph_dispatcher.py:101] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:21:07 [loggers.py:123] Engine 000: Avg prompt throughput: 328.2 tokens/s, Avg generation throughput: 23.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 17.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40016 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:21:17 [loggers.py:123] Engine 000: Avg prompt throughput: 80.8 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 28.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:21:27 [loggers.py:123] Engine 000: Avg prompt throughput: 99.5 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 34.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44582 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:21:37 [loggers.py:123] Engine 000: Avg prompt throughput: 169.2 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 42.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33980 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:21:47 [loggers.py:123] Engine 000: Avg prompt throughput: 291.8 tokens/s, Avg generation throughput: 30.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 41.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40752 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:21:57 [loggers.py:123] Engine 000: Avg prompt throughput: 104.0 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 42.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:22:07 [loggers.py:123] Engine 000: Avg prompt throughput: 193.5 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 45.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59224 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:22:17 [loggers.py:123] Engine 000: Avg prompt throughput: 135.1 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 45.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:22:27 [loggers.py:123] Engine 000: Avg prompt throughput: 259.4 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 45.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34368 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:22:37 [loggers.py:123] Engine 000: Avg prompt throughput: 358.3 tokens/s, Avg generation throughput: 30.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 42.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:22:47 [loggers.py:123] Engine 000: Avg prompt throughput: 143.4 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 42.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:22:57 [loggers.py:123] Engine 000: Avg prompt throughput: 326.7 tokens/s, Avg generation throughput: 30.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 41.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44666 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:23:07 [loggers.py:123] Engine 000: Avg prompt throughput: 90.6 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 42.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44672 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:23:17 [loggers.py:123] Engine 000: Avg prompt throughput: 304.1 tokens/s, Avg generation throughput: 30.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 42.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36828 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36840 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:23:27 [loggers.py:123] Engine 000: Avg prompt throughput: 146.3 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 42.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50278 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:23:37 [loggers.py:123] Engine 000: Avg prompt throughput: 256.4 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 42.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50292 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60088 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:23:47 [loggers.py:123] Engine 000: Avg prompt throughput: 119.7 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 42.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:23:57 [loggers.py:123] Engine 000: Avg prompt throughput: 287.0 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 42.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:24:07 [loggers.py:123] Engine 000: Avg prompt throughput: 115.9 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 42.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44706 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:24:17 [loggers.py:123] Engine 000: Avg prompt throughput: 234.4 tokens/s, Avg generation throughput: 29.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 41.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59368 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:24:27 [loggers.py:123] Engine 000: Avg prompt throughput: 86.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 43.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60116 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:24:37 [loggers.py:123] Engine 000: Avg prompt throughput: 99.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 43.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:24:47 [loggers.py:123] Engine 000: Avg prompt throughput: 84.6 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 44.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40498 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:24:57 [loggers.py:123] Engine 000: Avg prompt throughput: 83.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 45.8%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:25:07 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 45.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:25:17 [loggers.py:123] Engine 000: Avg prompt throughput: 84.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 46.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49356 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:25:27 [loggers.py:123] Engine 000: Avg prompt throughput: 83.4 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 47.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:25:37 [loggers.py:123] Engine 000: Avg prompt throughput: 83.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 48.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41664 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:25:47 [loggers.py:123] Engine 000: Avg prompt throughput: 83.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 49.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:25:57 [loggers.py:123] Engine 000: Avg prompt throughput: 83.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 50.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:26:07 [loggers.py:123] Engine 000: Avg prompt throughput: 83.3 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 50.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:26:17 [loggers.py:123] Engine 000: Avg prompt throughput: 83.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 51.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46258 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:26:27 [loggers.py:123] Engine 000: Avg prompt throughput: 89.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 52.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:26:37 [loggers.py:123] Engine 000: Avg prompt throughput: 88.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 53.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46446 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:26:47 [loggers.py:123] Engine 000: Avg prompt throughput: 85.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 53.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34014 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:26:57 [loggers.py:123] Engine 000: Avg prompt throughput: 85.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 54.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39170 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:27:07 [loggers.py:123] Engine 000: Avg prompt throughput: 85.6 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 55.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:27:17 [loggers.py:123] Engine 000: Avg prompt throughput: 86.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 55.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:27:27 [loggers.py:123] Engine 000: Avg prompt throughput: 84.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 56.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:27:37 [loggers.py:123] Engine 000: Avg prompt throughput: 85.6 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 56.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44530 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:27:47 [loggers.py:123] Engine 000: Avg prompt throughput: 88.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 57.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:27:57 [loggers.py:123] Engine 000: Avg prompt throughput: 87.3 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 57.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60344 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:28:07 [loggers.py:123] Engine 000: Avg prompt throughput: 90.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 58.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41184 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:28:17 [loggers.py:123] Engine 000: Avg prompt throughput: 92.0 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 58.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:28:27 [loggers.py:123] Engine 000: Avg prompt throughput: 84.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 59.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55242 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:28:37 [loggers.py:123] Engine 000: Avg prompt throughput: 83.3 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 59.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42796 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:28:47 [loggers.py:123] Engine 000: Avg prompt throughput: 84.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 60.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:28:57 [loggers.py:123] Engine 000: Avg prompt throughput: 84.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 60.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46876 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:29:07 [loggers.py:123] Engine 000: Avg prompt throughput: 84.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 61.0%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:29:17 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:29:27 [loggers.py:123] Engine 000: Avg prompt throughput: 84.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36848 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:29:37 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 2.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 61.5%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:29:47 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 61.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45232 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45240 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45254 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45268 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55480 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:43:37 [loggers.py:123] Engine 000: Avg prompt throughput: 330.4 tokens/s, Avg generation throughput: 22.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 59.5%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:43:47 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 59.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41908 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:43:57 [loggers.py:123] Engine 000: Avg prompt throughput: 182.5 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 59.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45248 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:44:07 [loggers.py:123] Engine 000: Avg prompt throughput: 171.4 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 59.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55206 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:44:17 [loggers.py:123] Engine 000: Avg prompt throughput: 179.0 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 59.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53704 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:44:27 [loggers.py:123] Engine 000: Avg prompt throughput: 220.1 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 59.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49182 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:44:37 [loggers.py:123] Engine 000: Avg prompt throughput: 83.5 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 59.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:44:47 [loggers.py:123] Engine 000: Avg prompt throughput: 112.2 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 59.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39258 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:44:57 [loggers.py:123] Engine 000: Avg prompt throughput: 297.1 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 58.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55158 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:45:07 [loggers.py:123] Engine 000: Avg prompt throughput: 100.7 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 58.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:45:17 [loggers.py:123] Engine 000: Avg prompt throughput: 175.7 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 57.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51604 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:45:27 [loggers.py:123] Engine 000: Avg prompt throughput: 184.9 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 57.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59038 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54306 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:45:37 [loggers.py:123] Engine 000: Avg prompt throughput: 315.0 tokens/s, Avg generation throughput: 30.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 56.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54114 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:45:47 [loggers.py:123] Engine 000: Avg prompt throughput: 158.5 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 56.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54128 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:45:57 [loggers.py:123] Engine 000: Avg prompt throughput: 91.7 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 56.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43548 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:46:07 [loggers.py:123] Engine 000: Avg prompt throughput: 306.3 tokens/s, Avg generation throughput: 30.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 55.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39942 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:46:17 [loggers.py:123] Engine 000: Avg prompt throughput: 147.4 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 55.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:46:27 [loggers.py:123] Engine 000: Avg prompt throughput: 258.6 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 55.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58460 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:46:37 [loggers.py:123] Engine 000: Avg prompt throughput: 120.8 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 55.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55172 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:46:47 [loggers.py:123] Engine 000: Avg prompt throughput: 144.4 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 55.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:46:57 [loggers.py:123] Engine 000: Avg prompt throughput: 144.8 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 54.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51736 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:47:07 [loggers.py:123] Engine 000: Avg prompt throughput: 117.0 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 54.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37208 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:47:17 [loggers.py:123] Engine 000: Avg prompt throughput: 236.6 tokens/s, Avg generation throughput: 29.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 54.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42198 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:47:27 [loggers.py:123] Engine 000: Avg prompt throughput: 87.3 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 54.6%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:47:37 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 54.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55688 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:47:47 [loggers.py:123] Engine 000: Avg prompt throughput: 100.5 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 54.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:47:57 [loggers.py:123] Engine 000: Avg prompt throughput: 85.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 55.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47562 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:48:07 [loggers.py:123] Engine 000: Avg prompt throughput: 169.6 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 55.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47564 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:48:17 [loggers.py:123] Engine 000: Avg prompt throughput: 84.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 56.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56672 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:48:27 [loggers.py:123] Engine 000: Avg prompt throughput: 84.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 56.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43928 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:48:37 [loggers.py:123] Engine 000: Avg prompt throughput: 84.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 56.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34988 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:48:47 [loggers.py:123] Engine 000: Avg prompt throughput: 84.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 57.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56436 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:48:57 [loggers.py:123] Engine 000: Avg prompt throughput: 84.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 57.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:49:07 [loggers.py:123] Engine 000: Avg prompt throughput: 84.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 57.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59348 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:49:17 [loggers.py:123] Engine 000: Avg prompt throughput: 90.1 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 57.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57646 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:49:27 [loggers.py:123] Engine 000: Avg prompt throughput: 89.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 58.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47092 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:49:37 [loggers.py:123] Engine 000: Avg prompt throughput: 86.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 58.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36830 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:49:47 [loggers.py:123] Engine 000: Avg prompt throughput: 86.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 58.6%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:49:57 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 58.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59132 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:50:07 [loggers.py:123] Engine 000: Avg prompt throughput: 86.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 58.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:50:17 [loggers.py:123] Engine 000: Avg prompt throughput: 87.9 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 59.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45338 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:50:27 [loggers.py:123] Engine 000: Avg prompt throughput: 85.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 59.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:50:38 [loggers.py:123] Engine 000: Avg prompt throughput: 86.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 59.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:50:48 [loggers.py:123] Engine 000: Avg prompt throughput: 89.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 59.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:50:58 [loggers.py:123] Engine 000: Avg prompt throughput: 88.4 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 60.1%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:51:08 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 60.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42146 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:51:18 [loggers.py:123] Engine 000: Avg prompt throughput: 91.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 60.3%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:51:28 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 5.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 60.3%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:51:38 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 60.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47706 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47708 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47720 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47722 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44140 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:52:08 [loggers.py:123] Engine 000: Avg prompt throughput: 330.4 tokens/s, Avg generation throughput: 22.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 61.3%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:52:18 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 61.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36848 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:52:28 [loggers.py:123] Engine 000: Avg prompt throughput: 182.5 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43752 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:52:38 [loggers.py:123] Engine 000: Avg prompt throughput: 171.4 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:52:48 [loggers.py:123] Engine 000: Avg prompt throughput: 179.0 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 62.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52074 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45920 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:52:58 [loggers.py:123] Engine 000: Avg prompt throughput: 220.1 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50476 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:53:08 [loggers.py:123] Engine 000: Avg prompt throughput: 83.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:53:18 [loggers.py:123] Engine 000: Avg prompt throughput: 112.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 63.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44386 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:53:28 [loggers.py:123] Engine 000: Avg prompt throughput: 297.0 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 64.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60558 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:53:38 [loggers.py:123] Engine 000: Avg prompt throughput: 100.7 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:53:48 [loggers.py:123] Engine 000: Avg prompt throughput: 175.7 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 65.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47422 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43134 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:53:58 [loggers.py:123] Engine 000: Avg prompt throughput: 329.3 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 66.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46332 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:54:08 [loggers.py:123] Engine 000: Avg prompt throughput: 170.5 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 66.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45860 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:54:18 [loggers.py:123] Engine 000: Avg prompt throughput: 158.5 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 66.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56596 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:54:28 [loggers.py:123] Engine 000: Avg prompt throughput: 180.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:54:38 [loggers.py:123] Engine 000: Avg prompt throughput: 218.0 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 67.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:54:48 [loggers.py:123] Engine 000: Avg prompt throughput: 147.4 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 67.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54740 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55106 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:54:58 [loggers.py:123] Engine 000: Avg prompt throughput: 258.6 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 68.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:55:08 [loggers.py:123] Engine 000: Avg prompt throughput: 120.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 68.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:55:18 [loggers.py:123] Engine 000: Avg prompt throughput: 144.4 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 69.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36512 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44520 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:55:28 [loggers.py:123] Engine 000: Avg prompt throughput: 261.8 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 69.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:55:38 [loggers.py:123] Engine 000: Avg prompt throughput: 147.6 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 69.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:55:48 [loggers.py:123] Engine 000: Avg prompt throughput: 111.3 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 69.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56252 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:55:58 [loggers.py:123] Engine 000: Avg prompt throughput: 247.1 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 69.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52934 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:56:08 [loggers.py:123] Engine 000: Avg prompt throughput: 122.0 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 69.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52944 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:56:18 [loggers.py:123] Engine 000: Avg prompt throughput: 150.5 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 68.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59030 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:56:28 [loggers.py:123] Engine 000: Avg prompt throughput: 236.5 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 68.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:56:38 [loggers.py:123] Engine 000: Avg prompt throughput: 129.8 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 68.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41684 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:56:48 [loggers.py:123] Engine 000: Avg prompt throughput: 121.2 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 68.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47084 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43864 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:56:58 [loggers.py:123] Engine 000: Avg prompt throughput: 258.7 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 68.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:57:08 [loggers.py:123] Engine 000: Avg prompt throughput: 116.7 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 67.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52642 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:57:18 [loggers.py:123] Engine 000: Avg prompt throughput: 221.9 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:57:28 [loggers.py:123] Engine 000: Avg prompt throughput: 144.4 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 67.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34236 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:57:38 [loggers.py:123] Engine 000: Avg prompt throughput: 128.0 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 67.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:57:48 [loggers.py:123] Engine 000: Avg prompt throughput: 213.7 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34660 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:57:58 [loggers.py:123] Engine 000: Avg prompt throughput: 122.7 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 67.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34676 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52724 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:58:08 [loggers.py:123] Engine 000: Avg prompt throughput: 269.7 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 66.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:58:18 [loggers.py:123] Engine 000: Avg prompt throughput: 86.9 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33706 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:58:28 [loggers.py:123] Engine 000: Avg prompt throughput: 203.9 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:48474 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:58:38 [loggers.py:123] Engine 000: Avg prompt throughput: 103.7 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56148 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:58:48 [loggers.py:123] Engine 000: Avg prompt throughput: 137.0 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 66.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56154 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:58:58 [loggers.py:123] Engine 000: Avg prompt throughput: 109.8 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 66.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43944 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55312 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:59:08 [loggers.py:123] Engine 000: Avg prompt throughput: 214.6 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 66.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34866 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:59:18 [loggers.py:123] Engine 000: Avg prompt throughput: 120.6 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 66.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:59:28 [loggers.py:123] Engine 000: Avg prompt throughput: 128.4 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 66.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58806 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:59:38 [loggers.py:123] Engine 000: Avg prompt throughput: 245.3 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:59:48 [loggers.py:123] Engine 000: Avg prompt throughput: 152.5 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 65.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58954 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 10:59:58 [loggers.py:123] Engine 000: Avg prompt throughput: 129.1 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58964 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:00:08 [loggers.py:123] Engine 000: Avg prompt throughput: 266.1 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49700 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:00:18 [loggers.py:123] Engine 000: Avg prompt throughput: 97.0 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49716 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54154 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:00:28 [loggers.py:123] Engine 000: Avg prompt throughput: 272.2 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36156 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:00:38 [loggers.py:123] Engine 000: Avg prompt throughput: 249.6 tokens/s, Avg generation throughput: 30.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.6%, Prefix cache hit rate: 64.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:00:48 [loggers.py:123] Engine 000: Avg prompt throughput: 191.2 tokens/s, Avg generation throughput: 30.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 64.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53654 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:00:58 [loggers.py:123] Engine 000: Avg prompt throughput: 255.3 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 64.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:01:08 [loggers.py:123] Engine 000: Avg prompt throughput: 361.0 tokens/s, Avg generation throughput: 29.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.3%, Prefix cache hit rate: 63.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37330 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:01:18 [loggers.py:123] Engine 000: Avg prompt throughput: 232.3 tokens/s, Avg generation throughput: 30.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.5%, Prefix cache hit rate: 62.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:01:28 [loggers.py:123] Engine 000: Avg prompt throughput: 167.8 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 62.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46036 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:01:38 [loggers.py:123] Engine 000: Avg prompt throughput: 222.4 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 62.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34376 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:01:48 [loggers.py:123] Engine 000: Avg prompt throughput: 99.4 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:01:58 [loggers.py:123] Engine 000: Avg prompt throughput: 148.6 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 62.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58994 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:02:08 [loggers.py:123] Engine 000: Avg prompt throughput: 269.9 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:02:18 [loggers.py:123] Engine 000: Avg prompt throughput: 132.6 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 62.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44202 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:02:28 [loggers.py:123] Engine 000: Avg prompt throughput: 122.5 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 62.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44216 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:02:38 [loggers.py:123] Engine 000: Avg prompt throughput: 149.9 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 61.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55484 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:02:48 [loggers.py:123] Engine 000: Avg prompt throughput: 477.0 tokens/s, Avg generation throughput: 29.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 61.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44036 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:02:58 [loggers.py:123] Engine 000: Avg prompt throughput: 137.3 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 61.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44042 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:03:08 [loggers.py:123] Engine 000: Avg prompt throughput: 204.6 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 60.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54216 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53304 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:03:18 [loggers.py:123] Engine 000: Avg prompt throughput: 240.7 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 60.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:03:28 [loggers.py:123] Engine 000: Avg prompt throughput: 159.1 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 60.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:03:38 [loggers.py:123] Engine 000: Avg prompt throughput: 246.4 tokens/s, Avg generation throughput: 30.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.6%, Prefix cache hit rate: 60.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:03:48 [loggers.py:123] Engine 000: Avg prompt throughput: 89.4 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 60.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58424 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38972 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:03:58 [loggers.py:123] Engine 000: Avg prompt throughput: 266.2 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 60.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52678 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:04:08 [loggers.py:123] Engine 000: Avg prompt throughput: 180.5 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 59.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52680 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47710 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:04:18 [loggers.py:123] Engine 000: Avg prompt throughput: 227.7 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 59.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45008 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:04:28 [loggers.py:123] Engine 000: Avg prompt throughput: 89.0 tokens/s, Avg generation throughput: 30.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 59.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45016 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:04:38 [loggers.py:123] Engine 000: Avg prompt throughput: 87.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 60.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59292 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:04:48 [loggers.py:123] Engine 000: Avg prompt throughput: 100.5 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 60.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:04:58 [loggers.py:123] Engine 000: Avg prompt throughput: 85.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 60.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51268 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:05:08 [loggers.py:123] Engine 000: Avg prompt throughput: 84.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 60.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52174 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:05:18 [loggers.py:123] Engine 000: Avg prompt throughput: 85.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 60.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52184 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:05:28 [loggers.py:123] Engine 000: Avg prompt throughput: 84.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 60.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:05:38 [loggers.py:123] Engine 000: Avg prompt throughput: 84.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 60.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:05:48 [loggers.py:123] Engine 000: Avg prompt throughput: 84.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 60.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:05:58 [loggers.py:123] Engine 000: Avg prompt throughput: 84.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33794 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:06:08 [loggers.py:123] Engine 000: Avg prompt throughput: 84.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34054 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:06:18 [loggers.py:123] Engine 000: Avg prompt throughput: 84.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36302 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:06:28 [loggers.py:123] Engine 000: Avg prompt throughput: 90.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:06:38 [loggers.py:123] Engine 000: Avg prompt throughput: 89.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40230 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:06:48 [loggers.py:123] Engine 000: Avg prompt throughput: 86.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 61.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39468 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:06:58 [loggers.py:123] Engine 000: Avg prompt throughput: 86.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 61.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:07:08 [loggers.py:123] Engine 000: Avg prompt throughput: 86.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 61.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:32858 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:07:18 [loggers.py:123] Engine 000: Avg prompt throughput: 87.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:07:28 [loggers.py:123] Engine 000: Avg prompt throughput: 85.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51566 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:07:38 [loggers.py:123] Engine 000: Avg prompt throughput: 86.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.2%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:07:48 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35514 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:07:58 [loggers.py:123] Engine 000: Avg prompt throughput: 89.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38168 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:08:08 [loggers.py:123] Engine 000: Avg prompt throughput: 88.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:08:18 [loggers.py:123] Engine 000: Avg prompt throughput: 91.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50826 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:08:28 [loggers.py:123] Engine 000: Avg prompt throughput: 93.1 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.6%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:08:38 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 62.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59714 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:08:48 [loggers.py:123] Engine 000: Avg prompt throughput: 85.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60824 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:08:58 [loggers.py:123] Engine 000: Avg prompt throughput: 84.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56268 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:09:08 [loggers.py:123] Engine 000: Avg prompt throughput: 85.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:09:18 [loggers.py:123] Engine 000: Avg prompt throughput: 85.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58022 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:09:28 [loggers.py:123] Engine 000: Avg prompt throughput: 85.9 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:48930 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:09:38 [loggers.py:123] Engine 000: Avg prompt throughput: 85.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58940 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:09:48 [loggers.py:123] Engine 000: Avg prompt throughput: 85.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37308 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:09:58 [loggers.py:123] Engine 000: Avg prompt throughput: 86.0 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57974 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35090 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:10:08 [loggers.py:123] Engine 000: Avg prompt throughput: 171.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35102 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:10:18 [loggers.py:123] Engine 000: Avg prompt throughput: 85.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57626 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:10:28 [loggers.py:123] Engine 000: Avg prompt throughput: 85.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:10:38 [loggers.py:123] Engine 000: Avg prompt throughput: 86.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:10:48 [loggers.py:123] Engine 000: Avg prompt throughput: 86.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:10:58 [loggers.py:123] Engine 000: Avg prompt throughput: 85.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52126 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:11:08 [loggers.py:123] Engine 000: Avg prompt throughput: 86.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59936 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:11:18 [loggers.py:123] Engine 000: Avg prompt throughput: 86.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 64.2%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:11:28 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38414 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:11:38 [loggers.py:123] Engine 000: Avg prompt throughput: 87.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44260 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:11:48 [loggers.py:123] Engine 000: Avg prompt throughput: 85.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43230 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:11:58 [loggers.py:123] Engine 000: Avg prompt throughput: 94.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33390 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:12:08 [loggers.py:123] Engine 000: Avg prompt throughput: 87.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49372 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:12:18 [loggers.py:123] Engine 000: Avg prompt throughput: 87.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49050 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:12:28 [loggers.py:123] Engine 000: Avg prompt throughput: 85.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40668 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:12:38 [loggers.py:123] Engine 000: Avg prompt throughput: 87.3 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52886 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:12:48 [loggers.py:123] Engine 000: Avg prompt throughput: 89.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.9%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:12:58 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36244 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:13:08 [loggers.py:123] Engine 000: Avg prompt throughput: 88.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44324 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:13:18 [loggers.py:123] Engine 000: Avg prompt throughput: 85.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55444 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:13:28 [loggers.py:123] Engine 000: Avg prompt throughput: 98.1 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55048 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:13:38 [loggers.py:123] Engine 000: Avg prompt throughput: 84.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:13:48 [loggers.py:123] Engine 000: Avg prompt throughput: 168.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44554 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:13:58 [loggers.py:123] Engine 000: Avg prompt throughput: 84.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40976 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:14:08 [loggers.py:123] Engine 000: Avg prompt throughput: 84.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52996 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:14:18 [loggers.py:123] Engine 000: Avg prompt throughput: 84.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:14:28 [loggers.py:123] Engine 000: Avg prompt throughput: 85.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:14:38 [loggers.py:123] Engine 000: Avg prompt throughput: 86.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.8%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:14:48 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53932 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:14:58 [loggers.py:123] Engine 000: Avg prompt throughput: 110.8 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42410 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:15:08 [loggers.py:123] Engine 000: Avg prompt throughput: 93.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58086 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:15:18 [loggers.py:123] Engine 000: Avg prompt throughput: 86.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37198 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:15:28 [loggers.py:123] Engine 000: Avg prompt throughput: 94.3 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52706 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:15:38 [loggers.py:123] Engine 000: Avg prompt throughput: 88.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.1%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:15:48 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37882 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:15:58 [loggers.py:123] Engine 000: Avg prompt throughput: 86.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:16:08 [loggers.py:123] Engine 000: Avg prompt throughput: 88.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43230 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:16:18 [loggers.py:123] Engine 000: Avg prompt throughput: 110.1 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 66.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:16:28 [loggers.py:123] Engine 000: Avg prompt throughput: 86.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60370 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:16:38 [loggers.py:123] Engine 000: Avg prompt throughput: 90.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:16:48 [loggers.py:123] Engine 000: Avg prompt throughput: 96.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60708 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:16:58 [loggers.py:123] Engine 000: Avg prompt throughput: 96.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37220 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:17:08 [loggers.py:123] Engine 000: Avg prompt throughput: 85.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.5%, Prefix cache hit rate: 66.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:17:18 [loggers.py:123] Engine 000: Avg prompt throughput: 84.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49354 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:17:28 [loggers.py:123] Engine 000: Avg prompt throughput: 86.3 tokens/s, Avg generation throughput: 31.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:17:38 [loggers.py:123] Engine 000: Avg prompt throughput: 85.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60942 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:17:48 [loggers.py:123] Engine 000: Avg prompt throughput: 84.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:17:58 [loggers.py:123] Engine 000: Avg prompt throughput: 85.0 tokens/s, Avg generation throughput: 31.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:18:08 [loggers.py:123] Engine 000: Avg prompt throughput: 88.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50644 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:18:18 [loggers.py:123] Engine 000: Avg prompt throughput: 88.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47398 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:18:28 [loggers.py:123] Engine 000: Avg prompt throughput: 88.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44756 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:18:38 [loggers.py:123] Engine 000: Avg prompt throughput: 85.0 tokens/s, Avg generation throughput: 31.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:18:48 [loggers.py:123] Engine 000: Avg prompt throughput: 88.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:18:58 [loggers.py:123] Engine 000: Avg prompt throughput: 93.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45780 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:19:08 [loggers.py:123] Engine 000: Avg prompt throughput: 87.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:19:18 [loggers.py:123] Engine 000: Avg prompt throughput: 89.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58436 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:19:28 [loggers.py:123] Engine 000: Avg prompt throughput: 94.6 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43582 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:19:38 [loggers.py:123] Engine 000: Avg prompt throughput: 89.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.6%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:19:48 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 67.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56146 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:19:58 [loggers.py:123] Engine 000: Avg prompt throughput: 89.5 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47794 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:20:08 [loggers.py:123] Engine 000: Avg prompt throughput: 89.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39968 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:20:18 [loggers.py:123] Engine 000: Avg prompt throughput: 96.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:20:28 [loggers.py:123] Engine 000: Avg prompt throughput: 99.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:48450 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:20:38 [loggers.py:123] Engine 000: Avg prompt throughput: 85.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36136 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:20:48 [loggers.py:123] Engine 000: Avg prompt throughput: 89.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50738 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:20:58 [loggers.py:123] Engine 000: Avg prompt throughput: 86.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 68.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:21:08 [loggers.py:123] Engine 000: Avg prompt throughput: 88.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 68.1%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:21:18 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 68.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53934 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:21:28 [loggers.py:123] Engine 000: Avg prompt throughput: 85.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 68.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55384 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:21:38 [loggers.py:123] Engine 000: Avg prompt throughput: 89.1 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 68.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42742 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:21:48 [loggers.py:123] Engine 000: Avg prompt throughput: 88.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 68.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49570 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:21:58 [loggers.py:123] Engine 000: Avg prompt throughput: 91.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 68.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51380 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:22:08 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 19.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.3%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 11:22:18 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 68.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56616 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56620 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56622 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56626 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:41:38 [loggers.py:123] Engine 000: Avg prompt throughput: 169.3 tokens/s, Avg generation throughput: 7.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 68.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:41:48 [loggers.py:123] Engine 000: Avg prompt throughput: 171.5 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 67.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42630 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:41:58 [loggers.py:123] Engine 000: Avg prompt throughput: 87.1 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42752 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36702 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:42:08 [loggers.py:123] Engine 000: Avg prompt throughput: 192.9 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 67.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53184 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:42:18 [loggers.py:123] Engine 000: Avg prompt throughput: 94.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53192 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40732 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:42:28 [loggers.py:123] Engine 000: Avg prompt throughput: 304.4 tokens/s, Avg generation throughput: 30.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 67.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57094 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:42:38 [loggers.py:123] Engine 000: Avg prompt throughput: 110.3 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 67.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:42:48 [loggers.py:123] Engine 000: Avg prompt throughput: 88.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 67.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35652 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55962 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:42:58 [loggers.py:123] Engine 000: Avg prompt throughput: 258.8 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 67.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35822 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:43:08 [loggers.py:123] Engine 000: Avg prompt throughput: 166.1 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 67.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35830 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:43:18 [loggers.py:123] Engine 000: Avg prompt throughput: 105.9 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 67.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42318 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45152 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:43:28 [loggers.py:123] Engine 000: Avg prompt throughput: 371.0 tokens/s, Avg generation throughput: 30.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 67.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40184 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:43:38 [loggers.py:123] Engine 000: Avg prompt throughput: 149.7 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 66.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52436 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:43:48 [loggers.py:123] Engine 000: Avg prompt throughput: 175.7 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 66.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52438 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50814 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:43:58 [loggers.py:123] Engine 000: Avg prompt throughput: 260.6 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58296 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:44:08 [loggers.py:123] Engine 000: Avg prompt throughput: 93.5 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58274 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:44:18 [loggers.py:123] Engine 000: Avg prompt throughput: 223.2 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.5%, Prefix cache hit rate: 66.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58282 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:44:28 [loggers.py:123] Engine 000: Avg prompt throughput: 152.6 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 66.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54768 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33378 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:44:38 [loggers.py:123] Engine 000: Avg prompt throughput: 269.0 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 66.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33738 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:44:48 [loggers.py:123] Engine 000: Avg prompt throughput: 126.0 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 66.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33748 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:44:58 [loggers.py:123] Engine 000: Avg prompt throughput: 149.6 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 66.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43080 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:45:08 [loggers.py:123] Engine 000: Avg prompt throughput: 150.0 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 66.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53204 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42288 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:45:18 [loggers.py:123] Engine 000: Avg prompt throughput: 275.0 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 65.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35468 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:45:28 [loggers.py:123] Engine 000: Avg prompt throughput: 116.5 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:45:38 [loggers.py:123] Engine 000: Avg prompt throughput: 136.6 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43624 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:45:48 [loggers.py:123] Engine 000: Avg prompt throughput: 248.1 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:45:58 [loggers.py:123] Engine 000: Avg prompt throughput: 155.7 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 65.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57598 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:46:08 [loggers.py:123] Engine 000: Avg prompt throughput: 124.1 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57600 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33998 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:46:18 [loggers.py:123] Engine 000: Avg prompt throughput: 257.8 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35388 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:46:28 [loggers.py:123] Engine 000: Avg prompt throughput: 126.4 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55478 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:46:38 [loggers.py:123] Engine 000: Avg prompt throughput: 157.7 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 65.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:46:48 [loggers.py:123] Engine 000: Avg prompt throughput: 233.3 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43670 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:46:58 [loggers.py:123] Engine 000: Avg prompt throughput: 116.9 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43678 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33754 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:47:08 [loggers.py:123] Engine 000: Avg prompt throughput: 265.0 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:47:18 [loggers.py:123] Engine 000: Avg prompt throughput: 133.2 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42320 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:47:28 [loggers.py:123] Engine 000: Avg prompt throughput: 109.0 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:47:38 [loggers.py:123] Engine 000: Avg prompt throughput: 243.0 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51326 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:47:48 [loggers.py:123] Engine 000: Avg prompt throughput: 148.4 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 64.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:48098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:47:58 [loggers.py:123] Engine 000: Avg prompt throughput: 131.7 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 64.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:48110 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60870 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:48:08 [loggers.py:123] Engine 000: Avg prompt throughput: 190.7 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:48:18 [loggers.py:123] Engine 000: Avg prompt throughput: 115.7 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45180 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:48:28 [loggers.py:123] Engine 000: Avg prompt throughput: 108.9 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58538 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:48:38 [loggers.py:123] Engine 000: Avg prompt throughput: 257.2 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41232 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:48:48 [loggers.py:123] Engine 000: Avg prompt throughput: 101.6 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51638 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:48:58 [loggers.py:123] Engine 000: Avg prompt throughput: 123.4 tokens/s, Avg generation throughput: 31.4 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 64.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51650 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:49:08 [loggers.py:123] Engine 000: Avg prompt throughput: 125.8 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 64.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41612 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38538 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:49:18 [loggers.py:123] Engine 000: Avg prompt throughput: 240.0 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41874 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:49:28 [loggers.py:123] Engine 000: Avg prompt throughput: 149.3 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 64.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49326 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:49:38 [loggers.py:123] Engine 000: Avg prompt throughput: 157.7 tokens/s, Avg generation throughput: 31.1 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 64.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46722 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:49:48 [loggers.py:123] Engine 000: Avg prompt throughput: 270.0 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 64.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43906 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:49:58 [loggers.py:123] Engine 000: Avg prompt throughput: 140.7 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 64.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43916 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:50:08 [loggers.py:123] Engine 000: Avg prompt throughput: 102.2 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55068 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38964 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:50:18 [loggers.py:123] Engine 000: Avg prompt throughput: 282.6 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35158 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:50:28 [loggers.py:123] Engine 000: Avg prompt throughput: 254.8 tokens/s, Avg generation throughput: 30.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.7%, Prefix cache hit rate: 63.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35166 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:50:38 [loggers.py:123] Engine 000: Avg prompt throughput: 196.4 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.3%, Prefix cache hit rate: 63.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57210 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:50:48 [loggers.py:123] Engine 000: Avg prompt throughput: 265.7 tokens/s, Avg generation throughput: 31.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 63.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56918 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:50:58 [loggers.py:123] Engine 000: Avg prompt throughput: 366.3 tokens/s, Avg generation throughput: 29.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 2.3%, Prefix cache hit rate: 63.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56922 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:51:08 [loggers.py:123] Engine 000: Avg prompt throughput: 237.5 tokens/s, Avg generation throughput: 30.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.6%, Prefix cache hit rate: 63.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57286 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52362 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:51:18 [loggers.py:123] Engine 000: Avg prompt throughput: 286.2 tokens/s, Avg generation throughput: 30.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:51:28 [loggers.py:123] Engine 000: Avg prompt throughput: 119.6 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 63.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56540 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:51:38 [loggers.py:123] Engine 000: Avg prompt throughput: 104.6 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 63.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56548 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:51:48 [loggers.py:123] Engine 000: Avg prompt throughput: 153.8 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 62.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45500 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35894 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:51:58 [loggers.py:123] Engine 000: Avg prompt throughput: 280.3 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 62.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57802 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:52:08 [loggers.py:123] Engine 000: Avg prompt throughput: 137.8 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 62.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57818 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:52:18 [loggers.py:123] Engine 000: Avg prompt throughput: 127.7 tokens/s, Avg generation throughput: 31.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 62.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38978 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:52:28 [loggers.py:123] Engine 000: Avg prompt throughput: 155.1 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 62.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55034 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:56506 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:52:38 [loggers.py:123] Engine 000: Avg prompt throughput: 487.5 tokens/s, Avg generation throughput: 29.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 62.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42176 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:52:48 [loggers.py:123] Engine 000: Avg prompt throughput: 142.5 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 62.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:52:58 [loggers.py:123] Engine 000: Avg prompt throughput: 209.8 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.4%, Prefix cache hit rate: 62.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52614 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44342 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:53:08 [loggers.py:123] Engine 000: Avg prompt throughput: 251.1 tokens/s, Avg generation throughput: 30.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.4%, Prefix cache hit rate: 62.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:53:18 [loggers.py:123] Engine 000: Avg prompt throughput: 164.3 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 61.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42846 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:53:28 [loggers.py:123] Engine 000: Avg prompt throughput: 251.6 tokens/s, Avg generation throughput: 30.5 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.7%, Prefix cache hit rate: 61.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60982 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47560 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:53:38 [loggers.py:123] Engine 000: Avg prompt throughput: 214.8 tokens/s, Avg generation throughput: 31.3 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 61.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49528 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:53:48 [loggers.py:123] Engine 000: Avg prompt throughput: 156.4 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.0%, Prefix cache hit rate: 61.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:53:58 [loggers.py:123] Engine 000: Avg prompt throughput: 185.7 tokens/s, Avg generation throughput: 30.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.2%, Prefix cache hit rate: 61.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54076 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57628 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:54:08 [loggers.py:123] Engine 000: Avg prompt throughput: 238.1 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 61.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36884 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:54:18 [loggers.py:123] Engine 000: Avg prompt throughput: 95.6 tokens/s, Avg generation throughput: 30.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36892 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:54:28 [loggers.py:123] Engine 000: Avg prompt throughput: 93.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60018 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:54:38 [loggers.py:123] Engine 000: Avg prompt throughput: 107.1 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49524 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:54:48 [loggers.py:123] Engine 000: Avg prompt throughput: 92.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 61.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37454 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:54:58 [loggers.py:123] Engine 000: Avg prompt throughput: 90.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 61.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50738 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:55:08 [loggers.py:123] Engine 000: Avg prompt throughput: 91.9 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50744 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:55:18 [loggers.py:123] Engine 000: Avg prompt throughput: 91.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:59430 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:55:28 [loggers.py:123] Engine 000: Avg prompt throughput: 91.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 61.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33832 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:55:38 [loggers.py:123] Engine 000: Avg prompt throughput: 91.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:55:48 [loggers.py:123] Engine 000: Avg prompt throughput: 91.3 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36392 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:55:58 [loggers.py:123] Engine 000: Avg prompt throughput: 91.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44328 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:56:08 [loggers.py:123] Engine 000: Avg prompt throughput: 91.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54340 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:56:18 [loggers.py:123] Engine 000: Avg prompt throughput: 96.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60606 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:56:28 [loggers.py:123] Engine 000: Avg prompt throughput: 96.5 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:56:38 [loggers.py:123] Engine 000: Avg prompt throughput: 92.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41568 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:56:48 [loggers.py:123] Engine 000: Avg prompt throughput: 93.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.4%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:56:58 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 62.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51338 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:57:08 [loggers.py:123] Engine 000: Avg prompt throughput: 93.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 62.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54360 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:57:18 [loggers.py:123] Engine 000: Avg prompt throughput: 94.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35188 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:57:28 [loggers.py:123] Engine 000: Avg prompt throughput: 92.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41394 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:57:38 [loggers.py:123] Engine 000: Avg prompt throughput: 93.3 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36816 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:57:48 [loggers.py:123] Engine 000: Avg prompt throughput: 96.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.7%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:57:58 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 62.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:48746 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:58:08 [loggers.py:123] Engine 000: Avg prompt throughput: 95.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37784 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:58:18 [loggers.py:123] Engine 000: Avg prompt throughput: 97.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:58:28 [loggers.py:123] Engine 000: Avg prompt throughput: 99.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 62.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47828 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:58:38 [loggers.py:123] Engine 000: Avg prompt throughput: 92.4 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51264 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:58:48 [loggers.py:123] Engine 000: Avg prompt throughput: 91.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 62.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47300 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:58:58 [loggers.py:123] Engine 000: Avg prompt throughput: 92.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39510 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:59:08 [loggers.py:123] Engine 000: Avg prompt throughput: 92.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.1%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:59:18 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 63.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58396 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:59:28 [loggers.py:123] Engine 000: Avg prompt throughput: 92.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 63.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:59:38 [loggers.py:123] Engine 000: Avg prompt throughput: 92.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:32778 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:59:48 [loggers.py:123] Engine 000: Avg prompt throughput: 92.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45270 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 12:59:58 [loggers.py:123] Engine 000: Avg prompt throughput: 92.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37798 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:00:08 [loggers.py:123] Engine 000: Avg prompt throughput: 92.0 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60044 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:00:18 [loggers.py:123] Engine 000: Avg prompt throughput: 92.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:48728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:00:28 [loggers.py:123] Engine 000: Avg prompt throughput: 92.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:32902 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:00:38 [loggers.py:123] Engine 000: Avg prompt throughput: 92.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58948 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:00:48 [loggers.py:123] Engine 000: Avg prompt throughput: 92.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38732 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:00:58 [loggers.py:123] Engine 000: Avg prompt throughput: 93.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:55334 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:01:08 [loggers.py:123] Engine 000: Avg prompt throughput: 92.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 63.7%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:01:18 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 63.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53932 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:01:28 [loggers.py:123] Engine 000: Avg prompt throughput: 93.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 63.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:01:38 [loggers.py:123] Engine 000: Avg prompt throughput: 93.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 63.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41970 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:01:48 [loggers.py:123] Engine 000: Avg prompt throughput: 94.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:01:58 [loggers.py:123] Engine 000: Avg prompt throughput: 92.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54292 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:02:08 [loggers.py:123] Engine 000: Avg prompt throughput: 100.9 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 63.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42032 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:02:18 [loggers.py:123] Engine 000: Avg prompt throughput: 93.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.0%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:02:28 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:48772 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:02:38 [loggers.py:123] Engine 000: Avg prompt throughput: 93.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36904 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:02:48 [loggers.py:123] Engine 000: Avg prompt throughput: 92.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46420 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:02:58 [loggers.py:123] Engine 000: Avg prompt throughput: 93.9 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57536 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:03:08 [loggers.py:123] Engine 000: Avg prompt throughput: 95.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33040 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:03:18 [loggers.py:123] Engine 000: Avg prompt throughput: 95.1 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50622 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:03:28 [loggers.py:123] Engine 000: Avg prompt throughput: 92.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.3%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:03:38 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:37494 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:03:48 [loggers.py:123] Engine 000: Avg prompt throughput: 104.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40632 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:03:58 [loggers.py:123] Engine 000: Avg prompt throughput: 91.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60254 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:04:08 [loggers.py:123] Engine 000: Avg prompt throughput: 91.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41824 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:04:18 [loggers.py:123] Engine 000: Avg prompt throughput: 90.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52516 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:04:28 [loggers.py:123] Engine 000: Avg prompt throughput: 91.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:42004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:04:38 [loggers.py:123] Engine 000: Avg prompt throughput: 91.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53486 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:04:48 [loggers.py:123] Engine 000: Avg prompt throughput: 91.2 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:38986 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:04:58 [loggers.py:123] Engine 000: Avg prompt throughput: 91.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35440 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:05:08 [loggers.py:123] Engine 000: Avg prompt throughput: 93.0 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.8%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:05:18 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:33352 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:05:28 [loggers.py:123] Engine 000: Avg prompt throughput: 117.4 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 64.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58496 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:05:38 [loggers.py:123] Engine 000: Avg prompt throughput: 99.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 64.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:57522 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:05:48 [loggers.py:123] Engine 000: Avg prompt throughput: 93.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 64.9%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:05:58 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:39098 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:06:08 [loggers.py:123] Engine 000: Avg prompt throughput: 100.9 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 64.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53134 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:06:18 [loggers.py:123] Engine 000: Avg prompt throughput: 95.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44466 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:06:28 [loggers.py:123] Engine 000: Avg prompt throughput: 93.4 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41774 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:06:38 [loggers.py:123] Engine 000: Avg prompt throughput: 95.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.1%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:06:48 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35900 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:06:58 [loggers.py:123] Engine 000: Avg prompt throughput: 116.7 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:35854 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:07:08 [loggers.py:123] Engine 000: Avg prompt throughput: 93.4 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:46522 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:07:18 [loggers.py:123] Engine 000: Avg prompt throughput: 97.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40728 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:07:28 [loggers.py:123] Engine 000: Avg prompt throughput: 103.4 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.2%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:07:38 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.9%, Prefix cache hit rate: 65.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:47024 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:07:48 [loggers.py:123] Engine 000: Avg prompt throughput: 103.4 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54618 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45602 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:07:58 [loggers.py:123] Engine 000: Avg prompt throughput: 182.9 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45608 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:08:08 [loggers.py:123] Engine 000: Avg prompt throughput: 92.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50588 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:08:18 [loggers.py:123] Engine 000: Avg prompt throughput: 92.5 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52000 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:08:28 [loggers.py:123] Engine 000: Avg prompt throughput: 91.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40726 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:08:38 [loggers.py:123] Engine 000: Avg prompt throughput: 91.6 tokens/s, Avg generation throughput: 31.6 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53490 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:08:48 [loggers.py:123] Engine 000: Avg prompt throughput: 95.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45404 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:08:58 [loggers.py:123] Engine 000: Avg prompt throughput: 95.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.6%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:09:08 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.6%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:50002 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:09:18 [loggers.py:123] Engine 000: Avg prompt throughput: 95.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54084 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:09:28 [loggers.py:123] Engine 000: Avg prompt throughput: 91.6 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.7%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:45196 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:09:38 [loggers.py:123] Engine 000: Avg prompt throughput: 94.9 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60072 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:09:48 [loggers.py:123] Engine 000: Avg prompt throughput: 99.7 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.8%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:34428 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:09:58 [loggers.py:123] Engine 000: Avg prompt throughput: 93.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44240 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:10:08 [loggers.py:123] Engine 000: Avg prompt throughput: 96.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 65.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:51960 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:10:18 [loggers.py:123] Engine 000: Avg prompt throughput: 101.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 65.9%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:10:28 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 65.9%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:36958 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:10:38 [loggers.py:123] Engine 000: Avg prompt throughput: 95.9 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 66.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:40280 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:10:48 [loggers.py:123] Engine 000: Avg prompt throughput: 96.1 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.0%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43482 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:10:58 [loggers.py:123] Engine 000: Avg prompt throughput: 96.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54938 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:11:08 [loggers.py:123] Engine 000: Avg prompt throughput: 103.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:60694 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:11:18 [loggers.py:123] Engine 000: Avg prompt throughput: 105.8 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.1%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:48856 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:11:28 [loggers.py:123] Engine 000: Avg prompt throughput: 92.4 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.2%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:11:38 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 66.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:43094 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:11:48 [loggers.py:123] Engine 000: Avg prompt throughput: 95.8 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 66.2%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53532 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:11:58 [loggers.py:123] Engine 000: Avg prompt throughput: 93.1 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:53178 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:12:08 [loggers.py:123] Engine 000: Avg prompt throughput: 94.6 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.3%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:49842 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:12:18 [loggers.py:123] Engine 000: Avg prompt throughput: 92.4 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:41934 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:12:28 [loggers.py:123] Engine 000: Avg prompt throughput: 95.7 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.6%, Prefix cache hit rate: 66.4%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:12:38 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.8%, Prefix cache hit rate: 66.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:44272 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:12:48 [loggers.py:123] Engine 000: Avg prompt throughput: 95.3 tokens/s, Avg generation throughput: 31.8 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.4%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:54366 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:12:58 [loggers.py:123] Engine 000: Avg prompt throughput: 98.2 tokens/s, Avg generation throughput: 31.7 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.7%, Prefix cache hit rate: 66.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52004 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:13:08 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 27.6 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 66.5%
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:13:18 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 66.5%
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58658 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58674 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58682 - "GET /v1/health HTTP/1.1" 404 Not Found
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:58696 - "GET /v1/models HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO:     172.16.5.14:52070 - "POST /v1/chat/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=1465994)[0;0m INFO 09-06 13:49:18 [loggers.py:123] Engine 000: Avg prompt throughput: 340.8 tokens/s, Avg generation throughput: 31.2 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 1.1%, Prefix cache hit rate: 66.7%
